{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forty-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dynamic-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experimental-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Dropout, LeakyReLU, Flatten, \\\n",
    "    BatchNormalization, Conv2D,Conv2DTranspose, Activation, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hairy-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'F:\\\\images\\\\coffee cup icon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-concord",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polish-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# widths = []\n",
    "# heights = []\n",
    "# for image_filename in os.listdir(image_path + '\\\\sub'):\n",
    "    \n",
    "#     img = imread(image_path + '\\\\sub' + '\\\\' + image_filename)\n",
    "#     width, height, _ = img.shape\n",
    "#     widths.append(width)\n",
    "#     heights.append(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.jointplot(widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "single-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.median(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ruled-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.median(heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "actual-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes = (224, 224, 3)\n",
    "batch_size = 16\n",
    "dim = 28\n",
    "depth = 128\n",
    "input_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "billion-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "communist-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1028 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = image_gen.flow_from_directory(\n",
    "    directory=image_path,\n",
    "    target_size=image_shapes[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    save_format='jpg',\n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "toxic-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, image_shapes, batch_size, dim, depth, input_dim, dropout=0.0):\n",
    "        self.image_shapes = image_shapes\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        self.input_dim = input_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def generator(self):\n",
    "        generator = Sequential()\n",
    "\n",
    "        generator.add(Dense(self.dim * self.dim * self.depth, input_shape=[self.input_dim]))\n",
    "        generator.add(Reshape((self.dim, self.dim, self.depth)))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Activation('relu'))\n",
    "\n",
    "        generator.add(Conv2DTranspose(int(self.depth/2), kernel_size=(5, 5), strides=2, padding='same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Activation('relu'))\n",
    "\n",
    "        generator.add(Conv2DTranspose(int(self.depth/4), kernel_size=(5, 5), strides=2, padding='same'))\n",
    "        generator.add(BatchNormalization())\n",
    "        generator.add(Activation('relu'))\n",
    "\n",
    "        generator.add(Conv2DTranspose(3, kernel_size=(5, 5), strides=2, padding='same'))\n",
    "        generator.add(Activation('tanh'))\n",
    "        \n",
    "        return generator\n",
    "    \n",
    "    def discriminator(self):\n",
    "        discriminator = Sequential()\n",
    "        \n",
    "        discriminator.add(Conv2D(int(depth/4), kernel_size=(5, 5), strides=2, padding=\"same\",\n",
    "                                 input_shape=self.image_shapes))\n",
    "        discriminator.add(LeakyReLU())\n",
    "        discriminator.add(Dropout(self.dropout))\n",
    "        \n",
    "        discriminator.add(Conv2D(depth/2, kernel_size=(5, 5), strides=2, padding=\"same\"))\n",
    "        discriminator.add(LeakyReLU())\n",
    "        discriminator.add(Dropout(self.dropout))\n",
    "        \n",
    "        discriminator.add(Conv2D(depth, kernel_size=(5, 5), strides=2, padding=\"same\"))\n",
    "        discriminator.add(LeakyReLU())\n",
    "        discriminator.add(Dropout(self.dropout))\n",
    "        \n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dense(1))\n",
    "        discriminator.add(Activation('sigmoid'))\n",
    "        \n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hollywood-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCGAN = DCGAN(image_shapes, batch_size, dim, depth, input_dim, dropout=0.2)\n",
    "generator = DCGAN.generator()\n",
    "discriminator = DCGAN.discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broadband-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.summary()\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spiritual-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prerequisite-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.compile(loss='binary_crossentropy',\n",
    "#                       optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "overall-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "scenic-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outstanding-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.compile(loss=\"binary_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "miniature-organ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x27d99612310>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x27d996123a0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAN.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "alert-reply",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 224, 224, 3)       10394947  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 358977    \n",
      "=================================================================\n",
      "Total params: 10,753,924\n",
      "Trainable params: 10,394,499\n",
      "Non-trainable params: 359,425\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automatic-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(epochs):\n",
    "    \n",
    "    generator, discriminator = GAN.layers\n",
    "    number_of_batches = len(image_generator)\n",
    "\n",
    "    # Variables that will be used to plot the losses from the discriminator and\n",
    "    # the adversarial models\n",
    "    adversarial_loss = np.empty(shape=1)\n",
    "    discriminator_loss = np.empty(shape=1)\n",
    "    batches = np.empty(shape=1)\n",
    "\n",
    "    # Allo plot updates inside for loop\n",
    "    plt.ion()\n",
    "\n",
    "    current_batch = 0\n",
    "\n",
    "    # Let's train the DCGAN for n epochs\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        print(\"Epoch \" + str(epoch) + \"/\" + str(epochs) + \" :\")\n",
    "\n",
    "        for batch_number in range(number_of_batches):\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Get the current batch and normalize the images between -1 and 1\n",
    "            real_images = image_generator.next()\n",
    "            real_images /= 127.5\n",
    "            real_images -= 1\n",
    "\n",
    "            # The last batch is smaller than the other ones, so we need to\n",
    "            # take that into account\n",
    "            current_batch_size = real_images.shape[0]\n",
    "\n",
    "            # Generate noise\n",
    "            noise = tf.random.normal(shape=[current_batch_size, input_dim])\n",
    "\n",
    "            # Generate images\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            X_fake_vs_real = tf.concat([generated_images, tf.dtypes.cast(real_images,tf.float32)], axis=0)\n",
    "            \n",
    "            y = tf.constant([[0.]] * current_batch_size + [[1.]] * current_batch_size)\n",
    "\n",
    "            # Let's train the discriminator\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            d_loss = discriminator.train_on_batch(X_fake_vs_real, y)\n",
    "\n",
    "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
    "\n",
    "            # Now it's time to train the generator\n",
    "            discriminator.trainable = False\n",
    "\n",
    "            noise = tf.random.normal(shape=[current_batch_size * 2, input_dim])\n",
    "\n",
    "            # We try to mislead the discriminator by giving the opposite labels\n",
    "            fake_y = np.ones(current_batch_size * 2)\n",
    "\n",
    "            g_loss = GAN.train_on_batch(noise, fake_y)\n",
    "            adversarial_loss = np.append(adversarial_loss ,g_loss)\n",
    "            batches = np.append(batches, current_batch)\n",
    "\n",
    "            # Each 50 batches show and save images\n",
    "#             if (batch_number + 1) % 10 == 0:\n",
    "#                 save_generated_images(generated_images, epoch, batch_number)\n",
    "\n",
    "            time_elapsed = time.time() - start_time\n",
    "\n",
    "            # Display and plot the results\n",
    "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
    "                  str(number_of_batches) +\n",
    "                  \" generator loss | discriminator loss : \" +\n",
    "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
    "                  str(time_elapsed) + ' s.')\n",
    "\n",
    "            current_batch += 1\n",
    "\n",
    "        # Save the model weights each 5 epochs\n",
    "        if epoch % 20 == 0:\n",
    "            discriminator.trainable = True\n",
    "            generator.save('models/generator_epoch_' + str(epoch) + '_' + str(adversarial_loss[-1]) + '.h5')\n",
    "            discriminator.save('models/discriminator_epoch_' +\n",
    "                               str(epoch)+ '_' + str(discriminator_loss[-1]) + '.h5')\n",
    "\n",
    "        # Each epoch update the loss graphs\n",
    "        plt.figure(1)\n",
    "        plt.plot(batches, adversarial_loss, color='green',\n",
    "                 label='Generator Loss')\n",
    "        plt.plot(batches, discriminator_loss, color='blue',\n",
    "                 label='Discriminator Loss')\n",
    "        plt.title(\"DCGAN Train\")\n",
    "        plt.xlabel(\"Batch Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        if epoch == 0:\n",
    "            plt.legend()\n",
    "        plt.pause(0.0000000001)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "familiar-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dcgan(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-shanghai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-flush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-symbol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-catch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-playback",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-learning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-blame",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
